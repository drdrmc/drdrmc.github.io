---
layout: post
title: Algorithms in decision-making
date: '2017-04-27T12:14:00.000+01:00'
author: Mac
tags: 
modified_time: '2017-05-31T12:15:22.849+01:00'
blogger_id: tag:blogger.com,1999:blog-2071817123910236284.post-3266473284318710744
blogger_orig_url: http://drdrmc.blogspot.com/2017/04/algorithms-in-decision-making.html
---





<div style="margin: 0pt; text-align: center;"><a href="http://data.parliament.uk/writtenevidence/committeeevidence.svc/evidencedocument/science-and-technology-committee/algorithms-in-decisionmaking/written/69082.html">Written evidence submitted by the Horizon Digital Economy Research Institute, University of Nottingham, and the Human Centred Computing group, University of Oxford, and (ALG0049)</span></a></div><div style="margin: 0pt; text-align: cleft;"> </div><br /><br >

<p style="margin:0pt; text-align:center"><span style="font-family:Arial; font-size:14pt">&nbsp;</span></p>
  <h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-align:justify; text-indent:-18pt; widows:0">
 <span style="font-family:Calibri; font-size:11pt">
  1. &nbsp;&nbsp;&nbsp;UnBias<a name="_ftnref1"></a><a href="#_ftn1">[1]</a><span style="font-family:Calibri; font-size:11pt"> is a research project funded under the Digital Economy theme’s Trust, Identity, Privacy and Security programme (EPSRC grant </span><span style="font-family:Calibri; font-size:11pt">EP/N02785X/1</span><span style="font-family:Calibri; font-size:11pt">).
 The project brings together researchers from the universities of 
Nottingham, Oxford and Edinburgh to study the user experience of 
algorithm driven internet services and the process of algorithm design 
with special attention to the experience of young people (13 to 17 years
 old) and issues related to non-operationally justified bias. </span><span style="font-family:Calibri; font-size:11pt">UnBias
 aims to provide policy recommendations, ethical guidelines and a 
‘fairness toolkit’ co-produced with young people and other stakeholders</span><span style="font-family:Calibri; font-size:11pt">. The toolkit</span><span style="font-family:Calibri; font-size:11pt">
 will include educational materials and resources to support youth 
understanding about online environments as well as raise awareness among
 online providers about the concerns and rights of young internet users.</span><span style="font-family:Calibri; font-size:11pt"> The draft report</span><a name="_ftnref2"></a><a href="#_ftn2">[2]</a><span style="font-family:Calibri; font-size:11pt">
 summarizing the outcomes of a set of case study discussions with 
stakeholders from academia, teachers, NGOs and SMEs has just been 
finalised.</span><a name="_GoBack"></a></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">2.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Prof</span><span style="font-family:Calibri; font-size:11pt">essor</span><span style="font-family:Calibri; font-size:11pt"> Derek McAuley, Dr </span><span style="font-family:Calibri; font-size:11pt">Ansgar</span><span style="font-family:Calibri; font-size:11pt"> </span><span style="font-family:Calibri; font-size:11pt">Koene</span><span style="font-family:Calibri; font-size:11pt"> and Dr Elvira Perez </span><span style="font-family:Calibri; font-size:11pt">Vallejos</span><span style="font-family:Calibri; font-size:11pt"> are part of </span><span style="font-family:Calibri; font-size:11pt">Horizon</span><span style="font-family:Calibri; font-size:11pt"> Digital Economy Research</span><a name="_ftnref3"></a><a href="#_ftn3">[3]</a><span style="font-family:Calibri; font-size:11pt"> which is a R</span><span style="font-family:Calibri; font-size:11pt">esearch Institute at The University of Nottingham </span><span style="font-family:Calibri; font-size:11pt">and a Research Hub within the RCUK Digital Economy programme</span><a name="_ftnref4"></a><a href="#_ftn4">[4]</a><span style="font-family:Calibri; font-size:11pt">.</span><span style="font-family:Calibri; font-size:11pt"> Horizon brings together researchers from a broad range of</span><span style="font-family:Calibri; font-size:11pt"> disciplines to investigate the opportunities and challenges arising from the increased use of </span><span style="font-family:Calibri; font-size:11pt">digital technology </span><span style="font-family:Calibri; font-size:11pt">in our everyday lives</span><span style="font-family:Calibri; font-size:11pt">.</span><span style="font-family:Calibri; font-size:11pt">
 Prof McAuley is Director of Horizon and principal investigator on the 
UnBias project. Dr Koene and Dr Perez Vallejos are Senior Research 
Fellows at Horizon and co-investigators on the UnBias</span><a name="_ftnref5"></a><a href="#_ftn5">[5]</a><span style="font-family:Calibri; font-size:11pt"> project. Dr Koene chairs the IEEE working group for the development of a Standards on Algorithm Bias Considerations</span><a name="_ftnref6"></a><a href="#_ftn6">[6]</a><span style="font-family:Calibri; font-size:11pt">.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">3.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Prof</span><span style="font-family:Calibri; font-size:11pt">essor</span><span style="font-family:Calibri; font-size:11pt"> Marina </span><span style="font-family:Calibri; font-size:11pt">Jirotka</span><span style="font-family:Calibri; font-size:11pt">, Dr </span><span style="font-family:Calibri; font-size:11pt">Menisha</span><span style="font-family:Calibri; font-size:11pt"> Patel, and Dr Helena Webb</span><span style="font-family:Calibri; font-size:11pt"> are part of the Human Centred Computing (HCC) group</span><a name="_ftnref7"></a><a href="#_ftn7">[7]</a><span style="font-family:Calibri; font-size:11pt">
 at the Department of Computer Science, University of Oxford. This is an
 interdisciplinary research group that seeks to increase understanding 
of how innovation impacts society and advance opportunities for new 
technologies to be developed in ways that are more responsive to 
societal acceptability and desirability. Prof Jirotka, and Dr Webb are 
co-investigators on the UnBias project.</span></h1><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">Questions</span></p><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">1. </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">The
 extent of current and future use of algorithms in decision-making in 
Government and public bodies, businesses and others, and the 
corresponding risks and opportunities</span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">.</span></p><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-align:justify; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">4.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">As
 part of the UnBias project we have been reviewing case studies of 
controversies over potential bias in algorithmic practice and scoping 
the informed opinion of stakeholders in this area (academics, educators,
 entrepreneurs, staff at platforms, NGOs, and staff at regulatory bodies
 etc.)</span><span style="font-family:Calibri; font-size:11pt">. </span><span style="font-family:Calibri; font-size:11pt">It
 is apparent that the ever-increasing use of algorithms to support 
decision-making, whilst providing opportunities for efficiency in 
practice, carries a great deal of risk relating to unfair or 
discriminatory outcomes. When considering the role of algorithms in 
decision making we need to think not only of cases where an algorithm is
 the complete and final arbiter of a decision process, but also the many
 cases where algorithms play a key role in shaping a decision process</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> even when the final decision is made by humans</span><span style="font-family:Calibri; font-size:11pt">; this may be illustrated by the</span><span style="font-family:Calibri; font-size:11pt"> now [in]famous example </span><span style="font-family:Calibri; font-size:11pt">of</span><span style="font-family:Calibri; font-size:11pt"> the sentencing support algorithm </span><span style="font-family:Calibri; font-size:11pt">used in some US courts which was shown to be biased</span><a name="_ftnref8"></a><a href="#_ftn8">[8]</a><span style="font-family:Calibri; font-size:11pt">.
 Given the ubiquitous nature of computer based processing of data, 
almost all services, be they government, public, business or otherwise, 
are in some way affected by algorithmic decision-making. As the 
complexity of these algorithmic practices increases, so do the inherent 
risks of bias as there are a greater number of stages in the process 
where errors can occur</span><span style="font-family:Calibri; font-size:11pt"> and accumulate</span><span style="font-family:Calibri; font-size:11pt">. These problems are in turn </span><span style="font-family:Calibri; font-size:11pt">exacerbated</span><span style="font-family:Calibri; font-size:11pt"> by the absence of oversight and effective regulation.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">5.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">The
 recent research work that we have conducted with young people has 
highlighted important concerns around algorithm use and trust issues. 
Results from a series of 'Youth Juries'</span><a name="_ftnref9"></a><a href="#_ftn9">[9]</a><span style="font-family:Calibri; font-size:11pt"> show that many young people experience a lack</span><span style="font-family:Calibri; font-size:11pt"> of trust toward the digital </span><span style="font-family:Calibri; font-size:11pt">world and </span><span style="font-family:Calibri; font-size:11pt">are </span><span style="font-family:Calibri; font-size:11pt">demand</span><span style="font-family:Calibri; font-size:11pt">ing</span><span style="font-family:Calibri; font-size:11pt"> a broader curriculum beyond the current provision of e-safety to help them understand algorithmic practices, </span><span style="font-family:Calibri; font-size:11pt">and to </span><span style="font-family:Calibri; font-size:11pt">increase
 their digital agency and confidence. Current use of algorithms in 
decision-making (e.g., job recruitment agencies) appears surprising to 
many young people, </span><span style="font-family:Calibri; font-size:11pt">e</span><span style="font-family:Calibri; font-size:11pt">specially
 for those unaware of such practices. Algorithms are perceived for most 
young people as a necessary mechanism to filter, rank or select large 
amounts of data but its opacity and lack of accessibility or 
transparency is </span><span style="font-family:Calibri; font-size:11pt">viewed with suspicion and undermines trust in the system</span><span style="font-family:Calibri; font-size:11pt">. </span><span style="font-family:Calibri; font-size:11pt">The </span><span style="font-family:Calibri; font-size:11pt">Youth Juries </span><span style="font-family:Calibri; font-size:11pt">also facilitated</span><span style="font-family:Calibri; font-size:11pt"> young people to deliberate together about what they require to regain </span><span style="font-family:Calibri; font-size:11pt">this </span><span style="font-family:Calibri; font-size:11pt">trust </span><span style="font-family:Calibri; font-size:11pt">– the request is for </span><span style="font-family:Calibri; font-size:11pt">a comprehensive digital education as well as for choices online to be meaningful and transparent.</span><span style="font-family:Calibri; font-size:11pt"> </span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt; orphans:0; widows:0"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">2. </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">Whether 'good practice' in algorithmic decision-making can be identified and spread, including in terms of:</span></h1><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">2a. </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">The scope for algorithmic decision-making to eliminate, introduce or amplify biases or discrimination, and how any such bi</span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">as can be detected and overcome?</span></p><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">6.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">When
 discussing bias in algorithmic decision-making it is important to start
 with a clear distinction between operationally-justified and 
non-operationally-justified bias. Justified bias prioritizes certain 
items/people as part of performing the desired task of the algorithm, 
e.g. identifying frail individuals when assigning medical 
prioritization. Non-operationally-justified bias by contrast is not 
integral to being able to do the task, and is often unintended and its 
presence is unknown unless explicitly looked for. </span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">7.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">In order to identify good practice related to biases or discrimination, some important processual issu</span><span style="font-family:Calibri; font-size:11pt">es must be taken into account, for example:</span></h1><ol style="margin:0pt; padding-left:0pt" type="I"><li style="font-family:Calibri; font-size:11pt; line-height:108%; margin:0pt 0pt 0pt 23.15pt; padding-left:13pt; text-indent:0pt"><span style="font-family:Calibri; font-size:11pt">In
 order to understand the scope for algorithmic decision-making in 
relation to bias adequately and appropriately, it is necessary to engage
 with</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> and integrate the views of</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt">
 multiple stakeholders to understand how algorithms are designed, 
developed and appropriated into the social world, how they have been 
experienced, and what </span><span style="font-family:Calibri; font-size:11pt">the </span><span style="font-family:Calibri; font-size:11pt">concerns surrounding their use are;</span></li><li style="font-family:Calibri; font-size:11pt; line-height:108%; margin:0pt 0pt 0pt 23.15pt; padding-left:13pt; text-indent:0pt"><span style="font-family:Calibri; font-size:11pt">Importantly, this undertaking and exploration should be </span><span style="font-family:Calibri; font-size:11pt">achieved </span><span style="font-family:Calibri; font-size:11pt">through rigorous research rather than abstract orientations towards good practice in relation to algorithms: </span><span style="font-family:Calibri; font-size:11pt">thus, </span><span style="font-family:Calibri; font-size:11pt">considering examples of the</span><span style="font-family:Calibri; font-size:11pt"> consequences </span><span style="font-family:Calibri; font-size:11pt">that people have experienced when algorithms</span><span style="font-family:Calibri; font-size:11pt"> have been implemented, particular scenarios surrounding their use, and as emphasised in the point above- talking to people</span><span style="font-family:Calibri; font-size:11pt"> about their experiences</span><span style="font-family:Calibri; font-size:11pt">.</span></li><li style="font-family:Calibri; font-size:11pt; line-height:108%; margin:0pt 0pt 6pt 23.15pt; padding-left:13pt; text-indent:0pt"><span style="font-family:Calibri; font-size:11pt">Given the complexities of the landscape in which algorithms are developed and used- we need to recognise that it is difficult, </span><span style="font-family:Calibri; font-size:11pt">in some cases </span><span style="font-family:Calibri; font-size:11pt">impossible,
 to develop completely unbiased algorithms and that this would be an 
unrealistic ideal to aim towards. Instead, it is important to base good 
practice on a balanced understanding and considering of 
multi-stakeholder needs.</span></li></ol><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">8.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">The
 need for ‘good practice’ guidance regarding bias in algorithmic 
decision-making has also been recognized by professional associations 
such as the Institute of Electrical and Electronic Engineers (IEEE) 
which in April 2016 launched a Global Initiative for Ethical 
Considerations in Artificial Intelligence and Autonomous system</span><a name="_ftnref10"></a><a href="#_ftn10">[10]</a><span style="font-family:Calibri; font-size:11pt">.
 As part of this initiative Dr Koene is chairing the working group for 
the development of a Standard on Algorithm Bias Considerations</span><a name="_ftnref11"></a><a href="#_ftn11">[11]</a><span style="font-family:Calibri; font-size:11pt">
 which will provide certification oriented methodologies to identify and
 mitigate non-operationally-justified algorithm biases through:</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 0pt 36pt; orphans:0; text-indent:-23.55pt; widows:0"><span style="font-family:Calibri; font-size:11pt">I.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">the use of benchmarking procedures</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 0pt 36pt; orphans:0; text-indent:-26.32pt; widows:0"><span style="font-family:Calibri; font-size:11pt">II.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">criteria for selecting bias validation data sets</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 0pt 36pt; orphans:0; text-indent:-29.09pt; widows:0"><span style="font-family:Calibri; font-size:11pt">III.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">guidelines for the</span><span style="font-family:Calibri; font-size:11pt"> </span><span style="font-family:Calibri; font-size:11pt">communication
 of application domain limitations (using the algorithm for purposes 
beyond this scope invalidates the certification)</span></h1><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt">&nbsp;</span></p><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">2b. </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">Whether
 and how algorithmic decision-making can be conducted in a ‘transparent’
 or ‘accountable’ way, and the scope for decisions made by an algorithm 
to be fully understood and challenged</span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">? </span></p><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">9.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">What is essential here is to create a </span><span style="font-family:Calibri; font-size:11pt; font-style:italic">meaningful transparency</span><span style="font-family:Calibri; font-size:11pt">: that is a transparency that all stakeholders can engage with, allowing the workings of</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> and practical implications of</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> algorithms to be accessible across the diverse stakeholder base that experience them.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">10.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">In
 order to create a meaningful transparency, we need to understand what 
stakeholders feel such a transparency would have to incorporate for them
 to be adequately informed</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> and </span><span style="font-family:Calibri; font-size:11pt">enable them</span><span style="font-family:Calibri; font-size:11pt">
 to engage with the positive and negative implications of algorithms. 
Though it is unlikely that there would be complete consensus, such 
stakeholder engagement can provide key insights for the nature and shape
 of solutions to be developed.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">11.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Importantly, this meaningful transparency should also relate to a </span><span style="font-family:Calibri; font-size:11pt; font-style:italic">meaningful accountability</span><span style="font-family:Calibri; font-size:11pt">. </span><span style="font-family:Calibri; font-size:11pt">It
 is not enough for stakeholders just to understand how algorithms are 
developed and how they make decisions.&nbsp; In making things 
meaningfully transparent, stakeholders should be given some agency to 
challenge algorithmic decision-making processes and outcomes.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">12.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">In
 principle, algorithmic decisions can be traced, step by step, to 
reconstruct how the outcome was arrived at. The problem with many of the
 more complex ‘big data’ type processes is the high </span><span style="font-family:Calibri; font-size:11pt">dimensionality</span><span style="font-family:Calibri; font-size:11pt"> of the underlying data</span><span style="font-family:Calibri; font-size:11pt">.
 This make it very difficult to comprehend which contributing factors 
are salient and which are effectively acting as noise (for </span><span style="font-family:Calibri; font-size:11pt">any given specific</span><span style="font-family:Calibri; font-size:11pt"> decision). </span><span style="font-family:Calibri; font-size:11pt">Analytic</span><span style="font-family:Calibri; font-size:11pt"> methods for dimension reduction can be used to make th</span><span style="font-family:Calibri; font-size:11pt">is more understandable in many situations,</span><span style="font-family:Calibri; font-size:11pt"> but may need to be applied </span><span style="font-family:Calibri; font-size:11pt">on a case-by-case b</span><span style="font-family:Calibri; font-size:11pt">asis to appropriately</span><span style="font-family:Calibri; font-size:11pt"> evaluate the important outlying and challenging </span><span style="font-family:Calibri; font-size:11pt">cases.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">13.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Similarly, it is important to note that many ‘big data’ and ‘artificial intelligence’ algorithms learn from </span><span style="font-family:Calibri; font-size:11pt">the
 data they are supplied with and modify their behaviour. We must look 
not only at the code that constitutes and algorithm, but the “training 
data” from which it learns. Practically this is becoming increasingly 
difficult as algorithms become embedded in off the shelf software 
packages and cloud services, where the algorithm itself is reused in 
various contexts and trained on different data – there is no one point 
at which the code and data are viewed together.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">14.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">The IEEE Global Initiative (s</span><span style="font-family:Calibri; font-size:11pt">ee point 6</span><span style="font-family:Calibri; font-size:11pt">) are also working to establish a Standard for Transparency of Autonomous Systems</span><a name="_ftnref12"></a><a href="#_ftn12">[12]</a><span style="font-family:Calibri; font-size:11pt">
 which aims to set out measurable, testable levels of transparency. The 
working group for this standard is chaired by Prof. Alan Winfield</span><a name="_ftnref13"></a><a href="#_ftn13">[13]</a><span style="font-family:Calibri; font-size:11pt">.</span></h1><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="color:#2f5496; font-family:Calibri; font-size:11pt">&nbsp;</span></p><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">2c. </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">The implications of increased transparency in terms of copyright and commercial sensitivity, </span><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">and protection of an individual’s data</span></p><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">15.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">As mentioned in our responses to 2b,</span><span style="font-family:Calibri; font-size:11pt"> while there is a need for</span><span style="font-family:Calibri; font-size:11pt"> </span><span style="font-family:Calibri; font-size:11pt; font-style:italic">meaningful transparency</span><span style="font-family:Calibri; font-size:11pt">, this does not </span><span style="font-family:Calibri; font-size:11pt">require that copyrighted code (or </span><span style="font-family:Calibri; font-size:11pt">d</span><span style="font-family:Calibri; font-size:11pt">at</span><span style="font-family:Calibri; font-size:11pt">a</span><span style="font-family:Calibri; font-size:11pt">)
 is made public. Within the community currently researching this topic, a
 recurring suggestion is the use of a neutral (or government associated)
 auditing body that could be tasked with certifying algorithmic systems 
through a process of expert analysis. This algorithm auditing could be 
done under </span><span style="font-family:Calibri; font-size:11pt">a </span><span style="font-family:Calibri; font-size:11pt">non-disclosure-agreement,
 protecting the IP, and the individual data. A detailed discussion 
outlining arguments in favour of such an approach was developed in an 
open access publish</span><span style="font-family:Calibri; font-size:11pt">ed paper by Andrew Tutt with the title “An FDA for Algorithms”</span><a name="_ftnref14"></a><a href="#_ftn14">[14]</a><span style="font-family:Calibri; font-size:11pt">.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">16.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Even
 if the copyrighted code is not made public, somehow making aspects of 
the design of algorithms more visible may still be useful</span><span style="font-family:Calibri; font-size:11pt">. </span><span style="font-family:Calibri; font-size:11pt">We
 see how the food industry make elements of their produce accessible for
 consumers to allow for consumers to make informed decisions about what 
they purchase.&nbsp; </span><span style="font-family:Calibri; font-size:11pt">At this point it</span><span style="font-family:Calibri; font-size:11pt"> is difficult to say what is better/worse without full and proper engagement with industry and other stakeholders, as we </span><span style="font-family:Calibri; font-size:11pt">are currently engaged in </span><span style="font-family:Calibri; font-size:11pt">through the UnBias project.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">17.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">It
 is necessary to have a dialogue with industry to understand their 
genuine concerns surrounding increased transparency, and how a way 
forward can be forged. There are elements of business procedures which 
have to be made transparent already (e.g. the requirements for audit, 
health and safety, etc…) so it is not that they are unaccustomed to such
 requirements. However, given that there is an element of commercial 
sensitivity in this context, then it is important to see what 
suggestions they would have to allow for increased transparency. </span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">18.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">We should be careful that we do not give the impression that commercial interests supersede the rights of people to obtain</span><span style="font-family:Calibri; font-size:11pt"> information about themselves. </span><span style="font-family:Calibri; font-size:11pt">We
 should be cautious about assuming industry interests are more important
 than other ones, and move forward with a balanced approach.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">19.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">Finally,
 the traditional bargain between society and inventors has been the 
patent - disclosure to stimulate innovation in return for commercial 
protection – the question arises as to what role might patents play in 
transparency. However, the situation concerning software patents is 
globally complex, but then the issue of algorithmic transparency is 
rapidly becoming a global issue.</span></h1><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic; font-weight:bold">3.
 Methods for providing regulatory oversight of algorithmic 
decision-making, such as the rights described in the EU General Data 
Protection Regulation 2016</span></p><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">20.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">The right to explanation in GDPR is still open to interpretation </span><span style="font-family:Calibri; font-size:11pt">and
 the actual practice will become established as cases unfold when 
enforcement starts in 2018. For example, the right to recourse and to </span><span style="font-family:Calibri; font-size:11pt">challenge algorithm</span><span style="font-family:Calibri; font-size:11pt">ic made decisions, is </span><span style="font-family:Calibri; font-size:11pt">restrict</span><span style="font-family:Calibri; font-size:11pt">ed</span><span style="font-family:Calibri; font-size:11pt"> to decisions that are </span><span style="font-family:Calibri; font-size:11pt">made </span><span style="font-family:Calibri; font-size:11pt; font-style:italic">fully autonomously</span><span style="font-family:Calibri; font-size:11pt"> by </span><span style="font-family:Calibri; font-size:11pt">algorithm</span><span style="font-family:Calibri; font-size:11pt">s</span><span style="font-family:Calibri; font-size:11pt"> and that </span><span style="font-family:Calibri; font-size:11pt">have clearly </span><span style="font-family:Calibri; font-size:11pt; font-style:italic">significant</span><span style="font-family:Calibri; font-size:11pt"> impact on the person</span><span style="font-family:Calibri; font-size:11pt">
 – it will be some time before we understand how these clauses will be 
implemented, and with impending Brexit, whether the UK will continue to 
align with the EU on these interpretations</span><span style="font-family:Calibri; font-size:11pt">. </span><span style="font-family:Calibri; font-size:11pt">The recent paper by Wachter et al.</span><a name="_ftnref15"></a><a href="#_ftn15">[15]</a><span style="font-family:Calibri; font-size:11pt"> puts forward the case that much more is needed to deliver a ‘</span><span style="font-family:Calibri; font-size:11pt; font-style:italic">right to explanation’</span><span style="font-family:Calibri; font-size:11pt">.</span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 6pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">21.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">More
 broadly, it is our position as a project that open dialogue amongst key
 stakeholders is an important step towards advancing the responsible 
oversight of algorithmic decision-making. It is necessary to include the
 perspectives of those from a wide range of sectors</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> alongside government and industry</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt"> in order to scope concerns over the current and future use of algorithms</span><span style="font-family:Calibri; font-size:11pt">,</span><span style="font-family:Calibri; font-size:11pt">
 and to identify genuine opportunities for regulation that are both 
technically feasible and legally and societally valid. As noted above, 
the activities of the UnBias project include the scoping of opinion 
amongst a wide range of informed stakeholders. By promoting discussion 
between stakeholder groups we are working to identify potentially 
effective methods for oversight of algorithmic decision- making. From 
the work we have conducted in this area so far, it is clear (as 
described above) that transparency alone is not a meaningful solution to
 the potential problems caused by algorithmic practices. Regulatory 
oversight needs also to incorporate responsibility and accountability so
 that users affected by algorithmic-decision making have opportunities 
to 1) understand how decisions about them were reached and 2) challenge 
those decisions if they feel them to be unfair. As also noted above, 
suggestions emerging from our project stakeholder dialogue so far 
include the possibility of an expert auditing or ombudsman system that 
oversees practice and mediates disputes. Further suggestions, in line 
with developments by the IEEE and elsewhere, include the provision of 
industry standards and certificates. </span></h1><h1 style="font-size:11pt; font-weight:normal; line-height:108%; margin:0pt 0pt 0pt 18pt; orphans:0; text-indent:-18pt; widows:0"><span style="font-family:Calibri; font-size:11pt">22.</span><span style="font:7.0pt 'Times New Roman'">&nbsp;&nbsp; </span><span style="font-family:Calibri; font-size:11pt">The Council of Europe’s Committee of Experts on Internet Intermediaries (MSI-NET)</span><a name="_ftnref16"></a><a href="#_ftn16">[16]</a><span style="font-family:Calibri; font-size:11pt">
 is currently also exploring the human rights dimensions of automated 
data procession techniques (in particular algorithms) and possible 
regulatory implications. As part of this investigation a preliminary 
report</span><a name="_ftnref17"></a><a href="#_ftn17">[17]</a><span style="font-family:Calibri; font-size:11pt"> was published on February 20</span><span style="font-family:Calibri; font-size:7.33pt; vertical-align:super">th</span><span style="font-family:Calibri; font-size:11pt"> which includes a number of relevant case studies and recommendations that are applicable to the topic of this inquiry. </span></h1><p style="font-size:11pt; line-height:108%; margin:0pt"><span style="font-family:Calibri; font-size:11pt">&nbsp;</span></p><p style="font-size:11pt; line-height:108%; margin:0pt"><span style="font-family:Calibri; font-size:11pt">&nbsp;</span></p><p style="font-size:11pt; line-height:108%; margin:0pt 0pt 6pt"><span style="font-family:Calibri; font-size:11pt; font-style:italic">April 2017</span></p></div><hr style="width:33%; height:1px; text-align:left"><p style="margin:0pt"><a name="_ftn1"></a><a href="#_ftnref1">[1]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://unbias.wp.horizon.ac.uk/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://unbias.wp.horizon.ac.uk</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn2"></a><a href="#_ftnref2">[2]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://unbias.wp.horizon.ac.uk/wp-content/uploads/2016/08/UnBias_Stakeholder_1stWorkshop_report_draft_for_approval.pdf"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://unbias.wp.horizon.ac.uk/wp-content/uploads/2016/08/UnBias_Stakeholder_1stWorkshop_report_draft_for_approval.pdf</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn3"></a><a href="#_ftnref3">[3]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://www.horizon.ac.uk/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://www.horizon.ac.uk</span></a></p><p style="margin:0pt"><a name="_ftn4"></a><a href="#_ftnref4">[4]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://www.epsrc.ac.uk/links/councils/research-councils-uk-rcuk/digital-economy-research-rcuk/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://www.epsrc.ac.uk/links/councils/research-councils-uk-rcuk/digital-economy-research-rcuk/</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn5"></a><a href="#_ftnref5">[5]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://unbias.wp.horizon.ac.uk/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://unbias.wp.horizon.ac.uk</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn6"></a><a href="#_ftnref6">[6]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://standards.ieee.org/develop/project/7003.html"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://standards.ieee.org/develop/project/7003.html</span></a></p><p style="margin:0pt"><a name="_ftn7"></a><a href="#_ftnref7">[7]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://www.cs.ox.ac.uk/activities/HCC/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://www.cs.ox.ac.uk/activities/HCC/</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn8"></a><a href="#_ftnref8">[8]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn9"></a><a href="#_ftnref9">[9]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://oer.horizon.ac.uk/5rights-youth-juries/"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://oer.horizon.ac.uk/5rights-youth-juries/</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn10"></a><a href="#_ftnref10">[10]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://standards.ieee.org/develop/indconn/ec/autonomous_systems.html"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://standards.ieee.org/develop/indconn/ec/autonomous_systems.html</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn11"></a><a href="#_ftnref11">[11]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://standards.ieee.org/develop/project/7003.html"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://standards.ieee.org/develop/project/7003.html</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn12"></a><a href="#_ftnref12">[12]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://standards.ieee.org/develop/project/7001.html"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://standards.ieee.org/develop/project/7001.html</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn13"></a><a href="#_ftnref13">[13]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://people.uwe.ac.uk/Pages/person.aspx?accountname=campus\a-winfield"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://people.uwe.ac.uk/Pages/person.aspx?accountname=campus\a-winfield</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn14"></a><a href="#_ftnref14">[14]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2747994"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2747994</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn15"></a><a href="#_ftnref15">[15]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2903469"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2903469</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn16"></a><a href="#_ftnref16">[16]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="https://www.coe.int/en/web/freedom-expression/committee-of-experts-on-internet-intermediaries-msi-net-"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">https://www.coe.int/en/web/freedom-expression/committee-of-experts-on-internet-intermediaries-msi-net-</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><p style="margin:0pt"><a name="_ftn17"></a><a href="#_ftnref17">[17]</a><span style="font-family:Calibri; font-size:9pt"> </span><a href="http://rm.coe.int/doc/09000016806fe644"><span style="color:#0000ff; font-family:Calibri; font-size:9pt; text-decoration:underline">http://rm.coe.int/doc/09000016806fe644</span></a><span style="font-family:Calibri; font-size:9pt"> </span></p><